{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+BxLxljwNbqNH23PH/1SA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehsung/PUBH6886/blob/main/PUBH6886_Homework_2_EHS_COMPLETED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PUBH 6886 Homework 2\n",
        "## Completed by Edward Sung\n",
        "## Completed on 10/08/24"
      ],
      "metadata": {
        "id": "P8f3T9h6w4uH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: suppressWarnings() is used on train() since it generates a lot of warnings related to:\n",
        "\n",
        "Warning message:\n",
        "“Setting row names on a tibble is deprecated.”"
      ],
      "metadata": {
        "id": "f_g56-WW6S-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table of Contents\n",
        "\n",
        ">[Question 1 -- reg_data.csv](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=ZHnVPFtK8o4u)\n",
        "\n",
        ">>[(a)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=pfSf7x_r8wl6)\n",
        "\n",
        ">>[(b)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=hxX_AJVoACbB)\n",
        "\n",
        ">>[(c)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=MNdRQSq-Ap_s)\n",
        "\n",
        ">>[(d)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=DSSCtjokDtZx)\n",
        "\n",
        ">[Question 2 - mus14data.csv](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=uJvzd2EQGAKS)\n",
        "\n",
        ">>[Part I (Validation Set Approach)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=1OFhiC1lHWNc)\n",
        "\n",
        ">>>[(a)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=MeyMZsIuHY0q)\n",
        "\n",
        ">>>[(b)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=s4_8iv_zmvQ9)\n",
        "\n",
        ">>>[(c)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=0yNo8F55noPV)\n",
        "\n",
        ">>>[(d)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=EFSmWE3oKXdY)\n",
        "\n",
        ">>[Part II (Cross-Validation Approach)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=_GZDGS2LHqEk)\n",
        "\n",
        ">>>[(e)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=zwA7N23THwTM)\n",
        "\n",
        ">>>[(f)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=u4-hERaDjGbs)\n",
        "\n",
        ">>>[(g)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=daDFX3fS64JW)\n",
        "\n",
        ">>>[(h)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=UcpvcWVRMBup)\n",
        "\n",
        ">>>[(i)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=1BJMoeMnWV3S)\n",
        "\n",
        ">>>[(j)](#updateTitle=true&folderId=1r-g8wJfeKaGd9a8yLWY3NoKaegmzbrzB&scrollTo=estEZ2hScgeA)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "P-ELlsscGEWg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxg68i3vw2bt"
      },
      "outputs": [],
      "source": [
        "# Install Libraries\n",
        "install.packages(\"caret\")\n",
        "install.packages(\"ggplot2\")\n",
        "install.packages(\"pROC\")\n",
        "install.packages(\"naivebayes\")\n",
        "install.packages(\"psych\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "library(dplyr)\n",
        "library(caret)\n",
        "library(ggplot2)\n",
        "library(pROC)\n",
        "library(naivebayes)\n",
        "library(psych)\n",
        "library(readr)\n",
        "library(class)\n",
        "library(MASS)"
      ],
      "metadata": {
        "id": "BL2_PCzq3NMN"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1 -- reg_data.csv\n",
        "(40 pts.) The csv file reg_data.csv contains simulated data with 200 observations on 7 variables: x1, x2,\n",
        "x3, x4, x5, x6, and y. In this problem, you will write your own code to conduct leave-one-out cross-validation\n",
        "(LOOCV) and 5-fold cross-validation (CV) to compute estimates for the test error of a linear model with y\n",
        "as the response and all other variables as predictors."
      ],
      "metadata": {
        "id": "ZHnVPFtK8o4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in data\n",
        "reg_data <- read_csv(\"/content/reg_data.csv\")\n",
        "\n",
        "# View data\n",
        "dim(reg_data)\n",
        "\n",
        "head(reg_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "Ez7vNfWg3Vu0",
        "outputId": "fe401066-931d-42d6-f9b5-9f703802b8f9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mRows: \u001b[22m\u001b[34m200\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m7\u001b[39m\n",
            "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
            "\u001b[1mDelimiter:\u001b[22m \",\"\n",
            "\u001b[32mdbl\u001b[39m (7): x1, x2, x3, x4, x5, x6, y\n",
            "\n",
            "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
            "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>200</li><li>7</li></ol>\n"
            ],
            "text/markdown": "1. 200\n2. 7\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 200\n\\item 7\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 200   7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 6 × 7</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>x1</th><th scope=col>x2</th><th scope=col>x3</th><th scope=col>x4</th><th scope=col>x5</th><th scope=col>x6</th><th scope=col>y</th></tr>\n",
              "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>-1.4805676</td><td>-2.98645607</td><td> 0.08712577</td><td>-1.4143294</td><td>-0.06748027</td><td>-2.5204781</td><td> 4.954282</td></tr>\n",
              "\t<tr><td> 1.5771695</td><td>-0.05054728</td><td>-1.36818436</td><td> 1.2760058</td><td>-0.20285061</td><td> 0.5159200</td><td>14.328271</td></tr>\n",
              "\t<tr><td>-0.9567445</td><td> 1.29951288</td><td>-1.39008345</td><td>-0.1442224</td><td> 0.15804987</td><td> 1.5817516</td><td> 8.086903</td></tr>\n",
              "\t<tr><td>-0.9200052</td><td>-1.35140108</td><td> 0.30526776</td><td> 0.7335033</td><td>-0.24980420</td><td> 0.4900354</td><td> 6.889574</td></tr>\n",
              "\t<tr><td>-1.9976421</td><td>-0.94979891</td><td> 0.15537138</td><td>-0.6607897</td><td>-0.30466253</td><td> 1.1993885</td><td> 5.282593</td></tr>\n",
              "\t<tr><td>-0.2722960</td><td> 1.68610180</td><td> 0.21445206</td><td> 1.3705340</td><td>-0.44977789</td><td>-0.9967298</td><td>11.015119</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 6 × 7\n\n| x1 &lt;dbl&gt; | x2 &lt;dbl&gt; | x3 &lt;dbl&gt; | x4 &lt;dbl&gt; | x5 &lt;dbl&gt; | x6 &lt;dbl&gt; | y &lt;dbl&gt; |\n|---|---|---|---|---|---|---|\n| -1.4805676 | -2.98645607 |  0.08712577 | -1.4143294 | -0.06748027 | -2.5204781 |  4.954282 |\n|  1.5771695 | -0.05054728 | -1.36818436 |  1.2760058 | -0.20285061 |  0.5159200 | 14.328271 |\n| -0.9567445 |  1.29951288 | -1.39008345 | -0.1442224 |  0.15804987 |  1.5817516 |  8.086903 |\n| -0.9200052 | -1.35140108 |  0.30526776 |  0.7335033 | -0.24980420 |  0.4900354 |  6.889574 |\n| -1.9976421 | -0.94979891 |  0.15537138 | -0.6607897 | -0.30466253 |  1.1993885 |  5.282593 |\n| -0.2722960 |  1.68610180 |  0.21445206 |  1.3705340 | -0.44977789 | -0.9967298 | 11.015119 |\n\n",
            "text/latex": "A tibble: 6 × 7\n\\begin{tabular}{lllllll}\n x1 & x2 & x3 & x4 & x5 & x6 & y\\\\\n <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t -1.4805676 & -2.98645607 &  0.08712577 & -1.4143294 & -0.06748027 & -2.5204781 &  4.954282\\\\\n\t  1.5771695 & -0.05054728 & -1.36818436 &  1.2760058 & -0.20285061 &  0.5159200 & 14.328271\\\\\n\t -0.9567445 &  1.29951288 & -1.39008345 & -0.1442224 &  0.15804987 &  1.5817516 &  8.086903\\\\\n\t -0.9200052 & -1.35140108 &  0.30526776 &  0.7335033 & -0.24980420 &  0.4900354 &  6.889574\\\\\n\t -1.9976421 & -0.94979891 &  0.15537138 & -0.6607897 & -0.30466253 &  1.1993885 &  5.282593\\\\\n\t -0.2722960 &  1.68610180 &  0.21445206 &  1.3705340 & -0.44977789 & -0.9967298 & 11.015119\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  x1         x2          x3          x4         x5          x6        \n",
              "1 -1.4805676 -2.98645607  0.08712577 -1.4143294 -0.06748027 -2.5204781\n",
              "2  1.5771695 -0.05054728 -1.36818436  1.2760058 -0.20285061  0.5159200\n",
              "3 -0.9567445  1.29951288 -1.39008345 -0.1442224  0.15804987  1.5817516\n",
              "4 -0.9200052 -1.35140108  0.30526776  0.7335033 -0.24980420  0.4900354\n",
              "5 -1.9976421 -0.94979891  0.15537138 -0.6607897 -0.30466253  1.1993885\n",
              "6 -0.2722960  1.68610180  0.21445206  1.3705340 -0.44977789 -0.9967298\n",
              "  y        \n",
              "1  4.954282\n",
              "2 14.328271\n",
              "3  8.086903\n",
              "4  6.889574\n",
              "5  5.282593\n",
              "6 11.015119"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (a)\n",
        "(15 pts.) Write your own code to compute the LOOCV RMSE for the linear model. Provide the\n",
        "LOOCV estimate for the RMSE."
      ],
      "metadata": {
        "id": "pfSf7x_r8wl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute LOOCV RMSE\n",
        "n <- nrow(reg_data)\n",
        "rmse_values <- numeric(n)\n",
        "\n",
        "for (i in 1:n) {\n",
        "  # Leave one observation out\n",
        "  train_data <- reg_data[-i, ]\n",
        "  test_data <- reg_data[i, , drop = FALSE]\n",
        "\n",
        "  # Fit the model on the training data\n",
        "  train_model <- lm(y ~ x1 + x2 + x3 + x4 + x5 + x6, data = train_data)\n",
        "\n",
        "  # Predict the left-out observation\n",
        "  prediction <- predict(train_model, newdata = test_data)\n",
        "\n",
        "  # Calculate RMSE for this fold\n",
        "  rmse_values[i] <- (prediction - test_data$y)^2\n",
        "}\n",
        "\n",
        "# Calculate mean RMSE\n",
        "mean_rmse <- sqrt(mean(rmse_values))\n",
        "mean_rmse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Qye-dMed8bsf",
        "outputId": "c3ca58b6-2016-4752-f063-609250cc66c5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.61994648699978"
            ],
            "text/markdown": "1.61994648699978",
            "text/latex": "1.61994648699978",
            "text/plain": [
              "[1] 1.619946"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (b)\n",
        "(5 pts.) Use the train() function from the caret package to confirm that your LOOCV estimate is\n",
        "correct."
      ],
      "metadata": {
        "id": "hxX_AJVoACbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the train() with lm and LOOCV\n",
        "lm_reg_data_loocv <- suppressWarnings(train(x = reg_data[,1:6], y = reg_data$y,\n",
        "                                            method = \"lm\", trControl = trainControl(method = \"LOOCV\")))\n",
        "\n",
        "lm_reg_data_loocv$results$RMSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "qRo7EfiW9B2s",
        "outputId": "a7dc3d2b-2db9-410e-af26-642a23c3bef5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.61994648699978"
            ],
            "text/markdown": "1.61994648699978",
            "text/latex": "1.61994648699978",
            "text/plain": [
              "[1] 1.619946"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both my manually coded and package LOOCV RMSE match.\n",
        "\n",
        "RMSE = 1.61994648699978"
      ],
      "metadata": {
        "id": "CVO9uCwtANSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (c)\n",
        "(15 pts.) Write your own code to compute the 5-fold CV RMSE for the linear model. Provide the 5-fold\n",
        "CV estimate for the RMSE. Since the rows of the data set are already randomly ordered, use rows 1 -\n",
        "40 for fold 1, 41 - 80 for fold 2, 81 - 120, for fold 3, 121 - 160 for fold 4, and 161 - 200 for fold 5."
      ],
      "metadata": {
        "id": "MNdRQSq-Ap_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the 5 fold list\n",
        "cv_folds <- list(\n",
        "  fold1 = reg_data[1:40, ],\n",
        "  fold2 = reg_data[41:80, ],\n",
        "  fold3 = reg_data[81:120, ],\n",
        "  fold4 = reg_data[121:160, ],\n",
        "  fold5 = reg_data[161:200, ]\n",
        "  )\n",
        "\n",
        "rmse_values <- numeric(length(cv_folds))\n",
        "\n",
        "for (i in 1:length(cv_folds)) {\n",
        "  # Create training and testing sets for each fold\n",
        "  test_data <- cv_folds[[i]]\n",
        "  train_data <- do.call(rbind, cv_folds[-i])\n",
        "\n",
        "  # Fit the model on the training data\n",
        "  train_model <- lm(y ~ x1 + x2 + x3 + x4 + x5 + x6, data = train_data)\n",
        "\n",
        "  # Predict on the test data\n",
        "  predictions <- predict(train_model, newdata = test_data)\n",
        "\n",
        "  # Calculate RMSE for this fold\n",
        "  rmse_values[i] <- sqrt(mean((predictions - test_data$y)^2))\n",
        "}\n",
        "\n",
        "# Calculate mean RMSE\n",
        "mean_rmse <- mean(rmse_values)\n",
        "mean_rmse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "R_FH4D4oAq-b",
        "outputId": "012a3188-8ef6-48e8-bd72-19c8161171f0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.6230370311353"
            ],
            "text/markdown": "1.6230370311353",
            "text/latex": "1.6230370311353",
            "text/plain": [
              "[1] 1.623037"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (d)\n",
        "(5 pts.) Use the train() function from the caret package to confirm that your 5-fold CV estimate is\n",
        "correct. The trControl argument allows you to specify which observations will be used for training\n",
        "and which will be held out for testing in each iteration of resampling if you do not want to use the\n",
        "default randomly generated folds. Use the code below for the trControl argument to obtain a 5-fold\n",
        "CV estimate that uses the same folds as those specified in part (c)"
      ],
      "metadata": {
        "id": "DSSCtjokDtZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Provided trControl code\n",
        "trControl = trainControl(method = \"cv\",\n",
        "                         index = list(41:200, c(1:40,81:200), c(1:80,121:200),\n",
        "                                     c(1:120,161:200), 1:160),\n",
        "                         indexOut = list(1:40, 41:80, 81:120, 121:160, 161:200))\n",
        "\n",
        "# Use the train() with lm and trControl for 5-fold CV\n",
        "lm_reg_data_5cv <- suppressWarnings(train(x = reg_data[,1:6], y = reg_data$y,\n",
        "                                          method = \"lm\", trControl = trControl))\n",
        "\n",
        "lm_reg_data_5cv$results$RMSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "FoxhcI3aDTUP",
        "outputId": "f2807383-acfa-41c8-fe9f-c4f10382ad0a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.6230370311353"
            ],
            "text/markdown": "1.6230370311353",
            "text/latex": "1.6230370311353",
            "text/plain": [
              "[1] 1.623037"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both my manually coded and package cv RMSE match.\n",
        "\n",
        "RMSE = 1.6230370311353"
      ],
      "metadata": {
        "id": "EzMh6MlpF1Az"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2 - mus14data.csv\n",
        "(105 pts.) The csv file mus14data.csv contains data from a cross sectional survey of 3206 individuals on\n",
        "Medicare (source: Cameron & Trivedi 2010). Below you will construct and evaluate a set of classification\n",
        "models that predict whether or not an individual has private insurance (private) or not using the set of\n",
        "other variables shown in the table below as predictors."
      ],
      "metadata": {
        "id": "uJvzd2EQGAKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in data\n",
        "mus14data <- read_csv(\"/content/mus14data.csv\")\n",
        "\n",
        "# Trim data down to using specific predictors\n",
        "select_predictors <- c(\"private\", \"retire\", \"age\", \"hstatusg\", \"hhincome\", \"educyear\", \"married\", \"hisp\", \"chronic\")\n",
        "mus14data_selected <- mus14data %>%\n",
        "  dplyr::select(all_of(select_predictors))\n",
        "\n",
        "# Factor the catagorical variables\n",
        "mus14data_selected$retire <- factor(mus14data_selected$retire)\n",
        "mus14data_selected$hstatusg <- factor(mus14data_selected$hstatusg)\n",
        "mus14data_selected$married <- factor(mus14data_selected$married)\n",
        "mus14data_selected$hisp <- factor(mus14data_selected$hisp)\n",
        "\n",
        "# View data\n",
        "head(mus14data_selected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "wIFKjzPgGCbK",
        "outputId": "db7d41c0-edf1-49fb-cfad-cff1a48ebbd2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mRows: \u001b[22m\u001b[34m3206\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m35\u001b[39m\n",
            "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
            "\u001b[1mDelimiter:\u001b[22m \",\"\n",
            "\u001b[32mdbl\u001b[39m (35): personid, private, eprhi, age, hisp, white, female, educyear, marr...\n",
            "\n",
            "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
            "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 6 × 9</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>private</th><th scope=col>retire</th><th scope=col>age</th><th scope=col>hstatusg</th><th scope=col>hhincome</th><th scope=col>educyear</th><th scope=col>married</th><th scope=col>hisp</th><th scope=col>chronic</th></tr>\n",
              "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>0</td><td>0</td><td>62</td><td>0</td><td>0</td><td>12</td><td>0</td><td>0</td><td>3</td></tr>\n",
              "\t<tr><td>0</td><td>0</td><td>59</td><td>0</td><td>0</td><td>12</td><td>0</td><td>0</td><td>1</td></tr>\n",
              "\t<tr><td>0</td><td>1</td><td>60</td><td>1</td><td>0</td><td>13</td><td>0</td><td>0</td><td>2</td></tr>\n",
              "\t<tr><td>0</td><td>0</td><td>62</td><td>0</td><td>0</td><td>10</td><td>0</td><td>0</td><td>4</td></tr>\n",
              "\t<tr><td>0</td><td>0</td><td>54</td><td>0</td><td>0</td><td> 9</td><td>0</td><td>0</td><td>6</td></tr>\n",
              "\t<tr><td>0</td><td>1</td><td>62</td><td>1</td><td>0</td><td>12</td><td>1</td><td>0</td><td>0</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 6 × 9\n\n| private &lt;dbl&gt; | retire &lt;fct&gt; | age &lt;dbl&gt; | hstatusg &lt;fct&gt; | hhincome &lt;dbl&gt; | educyear &lt;dbl&gt; | married &lt;fct&gt; | hisp &lt;fct&gt; | chronic &lt;dbl&gt; |\n|---|---|---|---|---|---|---|---|---|\n| 0 | 0 | 62 | 0 | 0 | 12 | 0 | 0 | 3 |\n| 0 | 0 | 59 | 0 | 0 | 12 | 0 | 0 | 1 |\n| 0 | 1 | 60 | 1 | 0 | 13 | 0 | 0 | 2 |\n| 0 | 0 | 62 | 0 | 0 | 10 | 0 | 0 | 4 |\n| 0 | 0 | 54 | 0 | 0 |  9 | 0 | 0 | 6 |\n| 0 | 1 | 62 | 1 | 0 | 12 | 1 | 0 | 0 |\n\n",
            "text/latex": "A tibble: 6 × 9\n\\begin{tabular}{lllllllll}\n private & retire & age & hstatusg & hhincome & educyear & married & hisp & chronic\\\\\n <dbl> & <fct> & <dbl> & <fct> & <dbl> & <dbl> & <fct> & <fct> & <dbl>\\\\\n\\hline\n\t 0 & 0 & 62 & 0 & 0 & 12 & 0 & 0 & 3\\\\\n\t 0 & 0 & 59 & 0 & 0 & 12 & 0 & 0 & 1\\\\\n\t 0 & 1 & 60 & 1 & 0 & 13 & 0 & 0 & 2\\\\\n\t 0 & 0 & 62 & 0 & 0 & 10 & 0 & 0 & 4\\\\\n\t 0 & 0 & 54 & 0 & 0 &  9 & 0 & 0 & 6\\\\\n\t 0 & 1 & 62 & 1 & 0 & 12 & 1 & 0 & 0\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  private retire age hstatusg hhincome educyear married hisp chronic\n",
              "1 0       0      62  0        0        12       0       0    3      \n",
              "2 0       0      59  0        0        12       0       0    1      \n",
              "3 0       1      60  1        0        13       0       0    2      \n",
              "4 0       0      62  0        0        10       0       0    4      \n",
              "5 0       0      54  0        0         9       0       0    6      \n",
              "6 0       1      62  1        0        12       1       0    0      "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View class distribution\n",
        "table(mus14data_selected$private)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "tYxcf9i2Ln0K",
        "outputId": "ee59104d-b4a9-4488-fc43-841479977d52"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "   0    1 \n",
              "1965 1241 "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part I (Validation Set Approach)"
      ],
      "metadata": {
        "id": "1OFhiC1lHWNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (a)\n",
        "(16 pts.) Split the data in to training and validation sets with 70% in the training set and 30% in\n",
        "the test/validation set. Fit a logistic model on the training set and use the estimated model with a\n",
        "threshold of 50% to predict whether or not a subject has private insurance. Take a look at the p-values\n",
        "for the slopes. What do these p-values suggest about the majority of the predictors in the model?\n",
        "Justify your response. Provide an estimate for the test misclassification error. Construct the confusion\n",
        "matrix and compute the true positive rate for classifying an observation as having private insurance\n",
        "and also compute the false positive rate. Use the code below to obtain the row indices for the training\n",
        "and test/validation sets (these ensure a 70/30 split)."
      ],
      "metadata": {
        "id": "MeyMZsIuHY0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data 70% training set, 30% test/validation set\n",
        "set.seed(1234)\n",
        "\n",
        "train_ids <- sample(1:3206, size = ceiling(3206*0.70))\n",
        "test_ids <- setdiff(1:3206, train_ids)\n",
        "\n",
        "train_data <- mus14data_selected[train_ids, ]\n",
        "test_data <- mus14data_selected[test_ids, ]\n",
        "\n",
        "dim(train_data)\n",
        "dim(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "PEJtnClTHaUV",
        "outputId": "4c013a35-927f-4e7a-9e28-3e08aa4e232e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>2245</li><li>9</li></ol>\n"
            ],
            "text/markdown": "1. 2245\n2. 9\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 2245\n\\item 9\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 2245    9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>961</li><li>9</li></ol>\n"
            ],
            "text/markdown": "1. 961\n2. 9\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 961\n\\item 9\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 961   9"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit logistic model on train_data\n",
        "logistic_model <- glm(private ~ ., data = train_data, family = binomial(link = \"logit\"))\n",
        "\n",
        "# View p-values for the slopes\n",
        "summary(logistic_model)$coef"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "cpHuf5yIH6kL",
        "outputId": "e4cf003f-cfc1-4fe0-969d-8c35888f3603"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 9 × 4 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>z value</th><th scope=col>Pr(&gt;|z|)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>(Intercept)</th><td>-2.379801128</td><td>0.8986160284</td><td>-2.6482959</td><td>8.089869e-03</td></tr>\n",
              "\t<tr><th scope=row>retire1</th><td> 0.293587073</td><td>0.1019005730</td><td> 2.8811131</td><td>3.962734e-03</td></tr>\n",
              "\t<tr><th scope=row>age</th><td>-0.011599220</td><td>0.0133771437</td><td>-0.8670924</td><td>3.858914e-01</td></tr>\n",
              "\t<tr><th scope=row>hstatusg1</th><td> 0.342038803</td><td>0.1179895900</td><td> 2.8988897</td><td>3.744867e-03</td></tr>\n",
              "\t<tr><th scope=row>hhincome</th><td> 0.001759817</td><td>0.0008677028</td><td> 2.0281337</td><td>4.254660e-02</td></tr>\n",
              "\t<tr><th scope=row>educyear</th><td> 0.126996111</td><td>0.0174162133</td><td> 7.2918326</td><td>3.057670e-13</td></tr>\n",
              "\t<tr><th scope=row>married1</th><td> 0.705222182</td><td>0.1150117667</td><td> 6.1317394</td><td>8.692340e-10</td></tr>\n",
              "\t<tr><th scope=row>hisp1</th><td>-0.905710051</td><td>0.2447861336</td><td>-3.7000055</td><td>2.155948e-04</td></tr>\n",
              "\t<tr><th scope=row>chronic</th><td> 0.066214854</td><td>0.0358694612</td><td> 1.8459952</td><td>6.489290e-02</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 9 × 4 of type dbl\n\n| <!--/--> | Estimate | Std. Error | z value | Pr(&gt;|z|) |\n|---|---|---|---|---|\n| (Intercept) | -2.379801128 | 0.8986160284 | -2.6482959 | 8.089869e-03 |\n| retire1 |  0.293587073 | 0.1019005730 |  2.8811131 | 3.962734e-03 |\n| age | -0.011599220 | 0.0133771437 | -0.8670924 | 3.858914e-01 |\n| hstatusg1 |  0.342038803 | 0.1179895900 |  2.8988897 | 3.744867e-03 |\n| hhincome |  0.001759817 | 0.0008677028 |  2.0281337 | 4.254660e-02 |\n| educyear |  0.126996111 | 0.0174162133 |  7.2918326 | 3.057670e-13 |\n| married1 |  0.705222182 | 0.1150117667 |  6.1317394 | 8.692340e-10 |\n| hisp1 | -0.905710051 | 0.2447861336 | -3.7000055 | 2.155948e-04 |\n| chronic |  0.066214854 | 0.0358694612 |  1.8459952 | 6.489290e-02 |\n\n",
            "text/latex": "A matrix: 9 × 4 of type dbl\n\\begin{tabular}{r|llll}\n  & Estimate & Std. Error & z value & Pr(>\\textbar{}z\\textbar{})\\\\\n\\hline\n\t(Intercept) & -2.379801128 & 0.8986160284 & -2.6482959 & 8.089869e-03\\\\\n\tretire1 &  0.293587073 & 0.1019005730 &  2.8811131 & 3.962734e-03\\\\\n\tage & -0.011599220 & 0.0133771437 & -0.8670924 & 3.858914e-01\\\\\n\thstatusg1 &  0.342038803 & 0.1179895900 &  2.8988897 & 3.744867e-03\\\\\n\thhincome &  0.001759817 & 0.0008677028 &  2.0281337 & 4.254660e-02\\\\\n\teducyear &  0.126996111 & 0.0174162133 &  7.2918326 & 3.057670e-13\\\\\n\tmarried1 &  0.705222182 & 0.1150117667 &  6.1317394 & 8.692340e-10\\\\\n\thisp1 & -0.905710051 & 0.2447861336 & -3.7000055 & 2.155948e-04\\\\\n\tchronic &  0.066214854 & 0.0358694612 &  1.8459952 & 6.489290e-02\\\\\n\\end{tabular}\n",
            "text/plain": [
              "            Estimate     Std. Error   z value    Pr(>|z|)    \n",
              "(Intercept) -2.379801128 0.8986160284 -2.6482959 8.089869e-03\n",
              "retire1      0.293587073 0.1019005730  2.8811131 3.962734e-03\n",
              "age         -0.011599220 0.0133771437 -0.8670924 3.858914e-01\n",
              "hstatusg1    0.342038803 0.1179895900  2.8988897 3.744867e-03\n",
              "hhincome     0.001759817 0.0008677028  2.0281337 4.254660e-02\n",
              "educyear     0.126996111 0.0174162133  7.2918326 3.057670e-13\n",
              "married1     0.705222182 0.1150117667  6.1317394 8.692340e-10\n",
              "hisp1       -0.905710051 0.2447861336 -3.7000055 2.155948e-04\n",
              "chronic      0.066214854 0.0358694612  1.8459952 6.489290e-02"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a p-value threshold of 0.05, a p-value less than that suggests that the predictor is statistically significant in predicting private insurance.\n",
        "\n",
        "The majority of the predictors have less than 0.05, thus most likely have meaningful contribution to the model in predicting private insurance. These predicators with less than 0.05 are: `retire`, `hstatusg`, `hhincome`, and `hisp`, with `educyear`, `married` having very low p-values, meaning they are the strongest predictors.\n",
        "\n",
        "`age` and `chronic` are not statistically significant at the p-value threshold, so they are not good predicators for private insurance."
      ],
      "metadata": {
        "id": "fOQO7kmDV226"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities on the test set using the trained model\n",
        "predicted_probs <- predict(logistic_model, newdata = test_data, type = \"response\")\n",
        "\n",
        "# Classify using a 50% threshold\n",
        "predicted_classes <- ifelse(predicted_probs > 0.5, 1, 0)\n",
        "\n",
        "# Generate confusiong matrix\n",
        "conf_matrix <- table(Predicted = predicted_classes, Actual = test_data$private)\n",
        "\n",
        "conf_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "UGT3cZC5U2Dv",
        "outputId": "0474fab0-4a93-4733-af34-4fb199ca71bb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         Actual\n",
              "Predicted   0   1\n",
              "        0 482 284\n",
              "        1 102  93"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell Values\n",
        "TP <- conf_matrix[2, 2]  # True Positives\n",
        "FN <- conf_matrix[1, 2]  # False Negatives\n",
        "FP <- conf_matrix[2, 1]  # False Positives\n",
        "TN <- conf_matrix[1, 1]  # True Negatives\n",
        "\n",
        "\n",
        "# Test correct classification (Accuracy)\n",
        "accuracy <- (TP + TN) / (TP + TN + FP + FN)\n",
        "print(paste(\"Accuracy:\", accuracy))\n",
        "\n",
        "# Test misclassification error (misclassification)\n",
        "misclassification <- 1 - accuracy\n",
        "print(paste(\"Misclassification Error:\", misclassification))\n",
        "\n",
        "# Test True Positive Rate (TPR)\n",
        "TPR <- TP / (TP + FN)\n",
        "print(paste(\"True Positive Rate (TPR):\", TPR))\n",
        "\n",
        "# Test False Positive Rate (FPR)\n",
        "FPR <- FP / (FP + TN)\n",
        "print(paste(\"False Positive Rate (FPR):\", FPR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QbmO_RaH_7x",
        "outputId": "01044c44-d684-4b6f-a06a-0b1ff7e3e5a0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Accuracy: 0.598335067637877\"\n",
            "[1] \"Misclassification Error: 0.401664932362123\"\n",
            "[1] \"True Positive Rate (TPR): 0.246684350132626\"\n",
            "[1] \"False Positive Rate (FPR): 0.174657534246575\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (b)\n",
        "(15 pts.) Using the validation data from part (a), provide histograms of the predicted probabilities in\n",
        "each outcome class, construct a calibration plot (bin the predicted probabilities into bins of length\n",
        "0.10), and compute Cohen’s κ. Collectively, do these diagnostics suggest that the classifier that you fit\n",
        "in part (a) performs well or performs poorly?"
      ],
      "metadata": {
        "id": "s4_8iv_zmvQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of predicted_probs on test_data\n",
        "results <- data.frame(\n",
        "  Actual = test_data$private,\n",
        "  Predicted_Prob = predicted_probs\n",
        ")\n",
        "\n",
        "ggplot(results, aes(x = Predicted_Prob)) +\n",
        "  geom_histogram(binwidth = 0.1, aes(fill = as.factor(Actual)), alpha = 0.8, boundary = 0) +\n",
        "  geom_vline(xintercept = 0.5, linetype = \"dashed\", color = \"black\", size = 1) +\n",
        "  facet_wrap(~Actual, scales = \"free\") +\n",
        "  scale_fill_manual(values = c(\"0\" = \"blue\", \"1\" = \"red\")) +\n",
        "  labs(title = \"Histograms of Predicted Probabilities by Class\",\n",
        "           x = \"Predicted Probability\",\n",
        "           y = \"Count\",\n",
        "        fill = \"Actual Class\") +\n",
        "  theme_minimal()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "_pTrxNKlbPym",
        "outputId": "2c6a401f-c2fd-455c-9f9c-71765cc78d88"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plot without title"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAACXBIWXMAABJ0AAASdAHeZh94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\nwQ4AAEASBDsAAABJ/C9fJheAS8EwwAAAAABJRU5ErkJggg=="
          },
          "metadata": {
            "image/png": {
              "width": 420,
              "height": 420
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calibration Plot on predicted_probs on test_data\n",
        "results$pred_bin <- cut(predicted_probs, breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1), include.lowest=TRUE)\n",
        "\n",
        "cal_data <- results %>%\n",
        "  group_by(pred_bin) %>%\n",
        "  summarize(event_prob = mean(Actual))\n",
        "\n",
        "cal_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "ZPbaqFcHsRyc",
        "outputId": "cd27813e-7350-4c31-e938-ed9ac082b636"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 8 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>pred_bin</th><th scope=col>event_prob</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>[0,0.1]  </td><td>0.05714286</td></tr>\n",
              "\t<tr><td>(0.1,0.2]</td><td>0.16494845</td></tr>\n",
              "\t<tr><td>(0.2,0.3]</td><td>0.30952381</td></tr>\n",
              "\t<tr><td>(0.3,0.4]</td><td>0.40500000</td></tr>\n",
              "\t<tr><td>(0.4,0.5]</td><td>0.50000000</td></tr>\n",
              "\t<tr><td>(0.5,0.6]</td><td>0.44347826</td></tr>\n",
              "\t<tr><td>(0.6,0.7]</td><td>0.51948052</td></tr>\n",
              "\t<tr><td>(0.7,0.8]</td><td>0.66666667</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 8 × 2\n\n| pred_bin &lt;fct&gt; | event_prob &lt;dbl&gt; |\n|---|---|\n| [0,0.1]   | 0.05714286 |\n| (0.1,0.2] | 0.16494845 |\n| (0.2,0.3] | 0.30952381 |\n| (0.3,0.4] | 0.40500000 |\n| (0.4,0.5] | 0.50000000 |\n| (0.5,0.6] | 0.44347826 |\n| (0.6,0.7] | 0.51948052 |\n| (0.7,0.8] | 0.66666667 |\n\n",
            "text/latex": "A tibble: 8 × 2\n\\begin{tabular}{ll}\n pred\\_bin & event\\_prob\\\\\n <fct> & <dbl>\\\\\n\\hline\n\t {[}0,0.1{]}   & 0.05714286\\\\\n\t (0.1,0.2{]} & 0.16494845\\\\\n\t (0.2,0.3{]} & 0.30952381\\\\\n\t (0.3,0.4{]} & 0.40500000\\\\\n\t (0.4,0.5{]} & 0.50000000\\\\\n\t (0.5,0.6{]} & 0.44347826\\\\\n\t (0.6,0.7{]} & 0.51948052\\\\\n\t (0.7,0.8{]} & 0.66666667\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  pred_bin  event_prob\n",
              "1 [0,0.1]   0.05714286\n",
              "2 (0.1,0.2] 0.16494845\n",
              "3 (0.2,0.3] 0.30952381\n",
              "4 (0.3,0.4] 0.40500000\n",
              "5 (0.4,0.5] 0.50000000\n",
              "6 (0.5,0.6] 0.44347826\n",
              "7 (0.6,0.7] 0.51948052\n",
              "8 (0.7,0.8] 0.66666667"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add bin midpoints for plotting\n",
        "cal_data$bin_mid <- c(0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75)\n",
        "\n",
        "# make claibration plot\n",
        "cal_data %>% ggplot(aes(x = bin_mid, y = event_prob)) +\n",
        "  geom_point() +\n",
        "  geom_abline(slope = 1, intercept = 0, lty = 2, col = \"grey\") +\n",
        "  ylab(\"Actual Event Percentage\") +\n",
        "  xlab(\"Bin Midpoint\") + xlim(0,0.8) +\n",
        "  theme_bw()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "LzRWQIWDt3OT",
        "outputId": "1968f3e2-a229-4c32-aa57-87dc124a1775"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plot without title"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC9FBMVEUAAAABAQECAgIDAwME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\nAYkohoBEFENAIoohIBHFEJCIYuj/A6IbURbhXzFtAAAAAElFTkSuQmCC"
          },
          "metadata": {
            "image/png": {
              "width": 420,
              "height": 420
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Computed Cohen's k on test_data\n",
        "cohen.kappa(cbind(test_data$private, predicted_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "gwNSrG1vj0b0",
        "outputId": "0cd25773-0799-400e-ad91-6035b15c929f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Call: cohen.kappa1(x = x, w = w, n.obs = n.obs, alpha = alpha, levels = levels, \n",
              "    w.exp = w.exp)\n",
              "\n",
              "Cohen Kappa and Weighted Kappa correlation coefficients and confidence boundaries \n",
              "                 lower estimate upper\n",
              "unweighted kappa 0.021    0.079  0.14\n",
              "weighted kappa   0.021    0.079  0.14\n",
              "\n",
              " Number of subjects = 961 "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram, calibration plot, and computed cohen's k on the test_data collectively suggests that the logistic regression model fit on the training data with a 0.5 threshold is performing poorly.\n",
        "\n",
        "In the histogram, the 0.5 threshold is marked as a dash line in both graphs. We can see for actual class 0 (blue graph), the majority of the predictions are on the left side of the dash, suggesting the model does do okay when predicting no private insurance, but does very poorly when trying to predict having private insurance as seen in the actual class 1 (red graph). For the samples that do have private insurance, the model has predicted that they didn't have insurnace, as shown by the majority counts are on the left side of the 0.5 threshold line.\n",
        "\n",
        "\n",
        "For the calibration plot, well-calibrated prediction probabilities would fall along the 45 degree line. But as seen in our graph, the points are above and below the 45 degree line.\n",
        "\n",
        "Cohen Kappa value for the test_data is 0.079, which is very close to 0. This means there are essentially no agreement between observed and predicted classes."
      ],
      "metadata": {
        "id": "KsY3A0dOm4nc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (c)\n",
        " (12 pts.) Suppose that you want to determine if there is a better threshold than 50%. Construct an\n",
        "ROC curve and compute the AUC (based on the test/validation data) for the logistic model that you\n",
        "fit in part (a). What is the optimal threshold if we want the sum of the sensitivity and specificity to\n",
        "be maximized? Does the optimal threshold produce a good predictive model based on sensitivity and\n",
        "specificity? Justify your response."
      ],
      "metadata": {
        "id": "0yNo8F55noPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate ROC\n",
        "logit_roc <- roc(response = results$Actual, predictor = results$Predicted_Prob)\n",
        "logit_roc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "XJEM9Yx7no1p",
        "outputId": "71be6f81-39c8-4392-bf10-5e24233d6dc7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting levels: control = 0, case = 1\n",
            "\n",
            "Setting direction: controls < cases\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "roc.default(response = results$Actual, predictor = results$Predicted_Prob)\n",
              "\n",
              "Data: results$Predicted_Prob in 584 controls (results$Actual 0) < 377 cases (results$Actual 1).\n",
              "Area under the curve: 0.6324"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AUC is 0.6324."
      ],
      "metadata": {
        "id": "EWe-8DMZBw42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC Curve with optimal threshold point\n",
        "plot(logit_roc, print.thres = TRUE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "FKNNXTpenxB-",
        "outputId": "849d1636-e5e1-4e0a-f919-7c23abc6587d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plot without title"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAYAAAD958/bAAAACXBIWXMAABJ0AAASdAHeZh94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\nAAAAAGDq/g/4gUMOXxgblQAAAABJRU5ErkJggg=="
          },
          "metadata": {
            "image/png": {
              "width": 420,
              "height": 420
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimal threshold to maximize the sum of sensitivity and specificity is 0.375."
      ],
      "metadata": {
        "id": "qPkqsVZ49CB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities on the test set using the trained model\n",
        "predicted_probs <- predict(logistic_model, newdata = test_data, type = \"response\")\n",
        "\n",
        "# Classify using the optimal threshold found in ROC\n",
        "predicted_classes <- ifelse(predicted_probs > 0.375, 1, 0)\n",
        "\n",
        "# Generate confusiong matrix\n",
        "conf_matrix <- table(Predicted = predicted_classes, Actual = test_data$private)\n",
        "\n",
        "conf_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "QXoeBQJ_7xTb",
        "outputId": "5d8a5377-415b-4c91-ad03-396e08e794bb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         Actual\n",
              "Predicted   0   1\n",
              "        0 315 117\n",
              "        1 269 260"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell Values\n",
        "TP <- conf_matrix[2, 2]  # True Positives\n",
        "FN <- conf_matrix[1, 2]  # False Negatives\n",
        "FP <- conf_matrix[2, 1]  # False Positives\n",
        "TN <- conf_matrix[1, 1]  # True Negatives\n",
        "\n",
        "\n",
        "# Test correct classification (Accuracy)\n",
        "accuracy <- (TP + TN) / (TP + TN + FP + FN)\n",
        "print(paste(\"Accuracy:\", accuracy))\n",
        "\n",
        "# Test misclassification error (misclassification)\n",
        "misclassification <- 1 - accuracy\n",
        "print(paste(\"Misclassification:\", misclassification))\n",
        "\n",
        "# Test True Positive Rate (TPR)\n",
        "TPR <- TP / (TP + FN)\n",
        "print(paste(\"True Positive Rate (TPR):\", TPR))\n",
        "\n",
        "# Test False Positive Rate (FPR)\n",
        "FPR <- FP / (FP + TN)\n",
        "print(paste(\"False Positive Rate (FPR):\", FPR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Asi_9u1k8ByI",
        "outputId": "5d77f5dc-b768-496d-82aa-56d056d360ad"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Accuracy: 0.598335067637877\"\n",
            "[1] \"Misclassification: 0.401664932362123\"\n",
            "[1] \"True Positive Rate (TPR): 0.689655172413793\"\n",
            "[1] \"False Positive Rate (FPR): 0.460616438356164\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The change from 0.5 --> 0.375 (optimal) classification threshold did not make a difference in relation to its overall predictive power, with the test misclassification error still being 0.402, the same as the 0.5 threshold. But the components that make up the misclassification error did change, with the number of true positives (predicting having private insurance) increasing and true negative (prediciting not haveing private insurance) decreasing.\n",
        "\n",
        "There was also a change in the TPR and FPR, both increasing in values respectively, which meant that decreasing the threshold lead to a better TPR at the exchange of a worse FPR.\n",
        "\n",
        "If our goal was to identify more people with private insurance, this new logistic regression model with a lower threshold does perform better as seen in the increase in True Positives and a higher TPR."
      ],
      "metadata": {
        "id": "iKYI16dl-ejD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (d)\n",
        "(10 pts.) Fit KNN classifiers on the training data set for K = 5, 10, 15, 20, 25, 30, 35, and 40 using all\n",
        "8 predictors. Use the validation set to select the optimal value of K based on misclassification error.\n",
        "How does the best-performing KNN model compare the the logistic model from part (a) with respect\n",
        "to misclassification error?"
      ],
      "metadata": {
        "id": "EFSmWE3oKXdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-load in data\n",
        "mus14data <- read_csv(\"/content/mus14data.csv\")\n",
        "\n",
        "# Trim data down to using specific predictors\n",
        "select_predictors <- c(\"private\", \"retire\", \"age\", \"hstatusg\", \"hhincome\", \"educyear\", \"married\", \"hisp\", \"chronic\")\n",
        "mus14data_selected <- mus14data %>%\n",
        "  dplyr::select(all_of(select_predictors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feT1tnStDJPY",
        "outputId": "a31fe8e6-698b-46e0-f8f1-cb7caa4ad28e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mRows: \u001b[22m\u001b[34m3206\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m35\u001b[39m\n",
            "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
            "\u001b[1mDelimiter:\u001b[22m \",\"\n",
            "\u001b[32mdbl\u001b[39m (35): personid, private, eprhi, age, hisp, white, female, educyear, marr...\n",
            "\n",
            "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
            "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Center and Scale the data\n",
        "mus14data_selected_csc <- data.frame(scale(mus14data_selected[,2:9]))\n",
        "mus14data_selected_csc$private <- mus14data_selected$private\n",
        "\n",
        "# Split data 70% training set, 30% test/validation set (Same split as previous)\n",
        "set.seed(1234)\n",
        "\n",
        "train_ids <- sample(1:3206, size = ceiling(3206*0.70))\n",
        "test_ids <- setdiff(1:3206, train_ids)\n",
        "\n",
        "train_data_csc <- mus14data_selected_csc[train_ids, ]\n",
        "test_data_csc <- mus14data_selected_csc[test_ids, ]\n",
        "\n",
        "# Holds the misclassification errors from the different K\n",
        "misclassification_error <- numeric(length = 8)\n",
        "k_values <- c(5, 10, 15, 20, 25, 30, 35, 40)\n",
        "\n",
        "# Loop through each value of k\n",
        "for (i in seq_along(k_values)) {\n",
        "  k <- k_values[i]  # Get the current value of k\n",
        "\n",
        "  # Fit the KNN model\n",
        "  knn_pred <- knn(train = train_data_csc[, 1:8],\n",
        "                  test = test_data_csc[, 1:8],\n",
        "                  cl = train_data_csc$private,\n",
        "                  k = k,\n",
        "                  prob = TRUE)\n",
        "\n",
        "  # Calculate misclassification error for specific knn_pred model\n",
        "  misclassification_error[i] <- mean(knn_pred != test_data_csc$private)\n",
        "\n",
        "  # Print the results\n",
        "  print(paste0(\"k = \", k, \" - Misclassification Error: \", misclassification_error[i]))\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDvPxh5NKYZL",
        "outputId": "727884b0-c1c7-4e38-d59a-4722afd3b611"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"k = 5 - Misclassification Error: 0.406867845993757\"\n",
            "[1] \"k = 10 - Misclassification Error: 0.398543184183143\"\n",
            "[1] \"k = 15 - Misclassification Error: 0.394380853277836\"\n",
            "[1] \"k = 20 - Misclassification Error: 0.406867845993757\"\n",
            "[1] \"k = 25 - Misclassification Error: 0.404786680541103\"\n",
            "[1] \"k = 30 - Misclassification Error: 0.413111342351717\"\n",
            "[1] \"k = 35 - Misclassification Error: 0.40894901144641\"\n",
            "[1] \"k = 40 - Misclassification Error: 0.399583766909469\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best K value based on lowest misclassification error is k=15 with a misclassification error of 0.394. It is essentially on the same level as the logistic classifier model made in (a), where its misclassification error was 0.402, a 0.008 difference."
      ],
      "metadata": {
        "id": "9QayswUdrfgY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II (Cross-Validation Approach)"
      ],
      "metadata": {
        "id": "_GZDGS2LHqEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (e)\n",
        "(10 pts.) Using the complete data set with all 3206 observations, compute the 10-fold CV misclassification\n",
        "error for the logistic classifier based on all 8 predictors and using a threshold of 50%. How does this\n",
        "compare with the estimate for the test misclassification error that you obtained in part (a)? On average,\n",
        "should we expect this value to be larger or smaller than the misclassification error obtained in part (a)?\n",
        "Justify your response."
      ],
      "metadata": {
        "id": "zwA7N23THwTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload the data\n",
        "mus14data <- read_csv(\"/content/mus14data.csv\")\n",
        "\n",
        "# Trim data down to using specific predictors\n",
        "select_predictors <- c(\"private\", \"retire\", \"age\", \"hstatusg\", \"hhincome\", \"educyear\", \"married\", \"hisp\", \"chronic\")\n",
        "mus14data_selected <- mus14data %>%\n",
        "  dplyr::select(all_of(select_predictors))\n",
        "\n",
        "# Factor the catagorical variables\n",
        "mus14data_selected$retire <- factor(mus14data_selected$retire)\n",
        "mus14data_selected$hstatusg <- factor(mus14data_selected$hstatusg)\n",
        "mus14data_selected$married <- factor(mus14data_selected$married)\n",
        "mus14data_selected$hisp <- factor(mus14data_selected$hisp)\n",
        "mus14data_selected$private <- factor(mus14data_selected$private,\n",
        "                                     levels = c(0, 1),\n",
        "                                     labels = c(\"class0\", \"class1\"))\n",
        "\n",
        "# Confirm data\n",
        "head(mus14data_selected)\n",
        "\n",
        "table(mus14data_selected$private)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "R5oGv_1HHtIc",
        "outputId": "ba5945a8-5447-49c3-c26e-44f30d6d872b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mRows: \u001b[22m\u001b[34m3206\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m35\u001b[39m\n",
            "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
            "\u001b[1mDelimiter:\u001b[22m \",\"\n",
            "\u001b[32mdbl\u001b[39m (35): personid, private, eprhi, age, hisp, white, female, educyear, marr...\n",
            "\n",
            "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
            "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 6 × 9</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>private</th><th scope=col>retire</th><th scope=col>age</th><th scope=col>hstatusg</th><th scope=col>hhincome</th><th scope=col>educyear</th><th scope=col>married</th><th scope=col>hisp</th><th scope=col>chronic</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>class0</td><td>0</td><td>62</td><td>0</td><td>0</td><td>12</td><td>0</td><td>0</td><td>3</td></tr>\n",
              "\t<tr><td>class0</td><td>0</td><td>59</td><td>0</td><td>0</td><td>12</td><td>0</td><td>0</td><td>1</td></tr>\n",
              "\t<tr><td>class0</td><td>1</td><td>60</td><td>1</td><td>0</td><td>13</td><td>0</td><td>0</td><td>2</td></tr>\n",
              "\t<tr><td>class0</td><td>0</td><td>62</td><td>0</td><td>0</td><td>10</td><td>0</td><td>0</td><td>4</td></tr>\n",
              "\t<tr><td>class0</td><td>0</td><td>54</td><td>0</td><td>0</td><td> 9</td><td>0</td><td>0</td><td>6</td></tr>\n",
              "\t<tr><td>class0</td><td>1</td><td>62</td><td>1</td><td>0</td><td>12</td><td>1</td><td>0</td><td>0</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA tibble: 6 × 9\n\n| private &lt;fct&gt; | retire &lt;fct&gt; | age &lt;dbl&gt; | hstatusg &lt;fct&gt; | hhincome &lt;dbl&gt; | educyear &lt;dbl&gt; | married &lt;fct&gt; | hisp &lt;fct&gt; | chronic &lt;dbl&gt; |\n|---|---|---|---|---|---|---|---|---|\n| class0 | 0 | 62 | 0 | 0 | 12 | 0 | 0 | 3 |\n| class0 | 0 | 59 | 0 | 0 | 12 | 0 | 0 | 1 |\n| class0 | 1 | 60 | 1 | 0 | 13 | 0 | 0 | 2 |\n| class0 | 0 | 62 | 0 | 0 | 10 | 0 | 0 | 4 |\n| class0 | 0 | 54 | 0 | 0 |  9 | 0 | 0 | 6 |\n| class0 | 1 | 62 | 1 | 0 | 12 | 1 | 0 | 0 |\n\n",
            "text/latex": "A tibble: 6 × 9\n\\begin{tabular}{lllllllll}\n private & retire & age & hstatusg & hhincome & educyear & married & hisp & chronic\\\\\n <fct> & <fct> & <dbl> & <fct> & <dbl> & <dbl> & <fct> & <fct> & <dbl>\\\\\n\\hline\n\t class0 & 0 & 62 & 0 & 0 & 12 & 0 & 0 & 3\\\\\n\t class0 & 0 & 59 & 0 & 0 & 12 & 0 & 0 & 1\\\\\n\t class0 & 1 & 60 & 1 & 0 & 13 & 0 & 0 & 2\\\\\n\t class0 & 0 & 62 & 0 & 0 & 10 & 0 & 0 & 4\\\\\n\t class0 & 0 & 54 & 0 & 0 &  9 & 0 & 0 & 6\\\\\n\t class0 & 1 & 62 & 1 & 0 & 12 & 1 & 0 & 0\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  private retire age hstatusg hhincome educyear married hisp chronic\n",
              "1 class0  0      62  0        0        12       0       0    3      \n",
              "2 class0  0      59  0        0        12       0       0    1      \n",
              "3 class0  1      60  1        0        13       0       0    2      \n",
              "4 class0  0      62  0        0        10       0       0    4      \n",
              "5 class0  0      54  0        0         9       0       0    6      \n",
              "6 class0  1      62  1        0        12       1       0    0      "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "class0 class1 \n",
              "  1965   1241 "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10-fold CV Logistic Classifier, train() default 50% threshold\n",
        "set.seed(1234)\n",
        "\n",
        "lr_mus14data_selected_10cv <- suppressWarnings(train(x = mus14data_selected[,2:9], y = mus14data_selected$private,\n",
        "                                                     method = \"glm\", family = binomial(link = \"logit\"),\n",
        "                                                     trControl = trainControl(method = \"cv\", number = 10,\n",
        "                                                     classProbs = TRUE, savePredictions = TRUE)))\n",
        "\n",
        "# Calculate misclassification error (1 - accuracy)\n",
        "misclassification_error = 1 - lr_mus14data_selected_10cv$results$Accuracy\n",
        "print(paste(\"Misclassification Error:\", misclassification_error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRZO-LYkH8VX",
        "outputId": "31af00ab-9225-4268-ce2b-9d0867198f90"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Misclassification Error: 0.378042982430681\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.402 - 0.378"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "hj-Ju4uEJTn1",
        "outputId": "dcd949eb-f4d4-4f1b-f93c-39dc95413c0e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.024"
            ],
            "text/markdown": "0.024",
            "text/latex": "0.024",
            "text/plain": [
              "[1] 0.024"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This 10-fold cv logistic classifier model has a lower test misclassification error of 0.378, a 0.024 difference compared to the validation apporach logistic classifer in (a) of 0.402.\n",
        "\n",
        "On average, we would expect k-fold CV misclassification error to be smaller than the validation set approach done in (a). This is because the k-fold CV is being trained and tested on different parts of the same dataset. The model would eventaully train on patterns that would be seen in the test set as it goes through the folds, leading to better predictions and lower misclassification.\n",
        "\n",
        "While validation set approach tests on a completely independent validation set, not seen by the model during training, that may have patterns not present in the training dataset, which will lead to more misclassification."
      ],
      "metadata": {
        "id": "GNACJeCeY4Qz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (f)\n",
        "(15 pts.) Using the complete data set with all 3206 observations, determine the optimal threshold for\n",
        "the logistic model fit in part (e) based on 10-fold CV misclassification error. Consider threshold values\n",
        "of 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, and 90%. Is the optimal threshold based on 10-fold CV\n",
        "misclassification error the same as the optimal threshold based on 10-fold CV Cohen’s κ? Justify your\n",
        "response."
      ],
      "metadata": {
        "id": "u4-hERaDjGbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequence of threshold values\n",
        "prob_thresh <- seq(0.10, 0.90, by = 0.10)\n",
        "prob_thresh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "tbOgODOBW1lF",
        "outputId": "c0bef8d7-2483-45c3-85b2-d8b51cbe314d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>0.1</li><li>0.2</li><li>0.3</li><li>0.4</li><li>0.5</li><li>0.6</li><li>0.7</li><li>0.8</li><li>0.9</li></ol>\n"
            ],
            "text/markdown": "1. 0.1\n2. 0.2\n3. 0.3\n4. 0.4\n5. 0.5\n6. 0.6\n7. 0.7\n8. 0.8\n9. 0.9\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 0.1\n\\item 0.2\n\\item 0.3\n\\item 0.4\n\\item 0.5\n\\item 0.6\n\\item 0.7\n\\item 0.8\n\\item 0.9\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use thresholder() function to obtain accuracy measures at each threshold\n",
        "lr_mus14data_selected_10cv_ths <- thresholder(lr_mus14data_selected_10cv,\n",
        "                                              threshold = prob_thresh,\n",
        "                                              final = TRUE,\n",
        "                                              statistics = c(\"Sensitivity\", \"Specificity\", \"Accuracy\", \"Kappa\"))\n",
        "\n",
        "# Calculate misclassification error\n",
        "lr_mus14data_selected_10cv_ths$misclassification_error <- 1 - lr_mus14data_selected_10cv_ths$Accuracy\n",
        "\n",
        "lr_mus14data_selected_10cv_ths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "GhopELnvjV6O",
        "outputId": "9251a9de-c19c-4d40-dc8e-4adbfa166da5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 9 × 7</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>parameter</th><th scope=col>prob_threshold</th><th scope=col>Sensitivity</th><th scope=col>Specificity</th><th scope=col>Accuracy</th><th scope=col>Kappa</th><th scope=col>misclassification_error</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>none</td><td>0.1</td><td>0.99898477</td><td>0.0008064516</td><td>0.6126015</td><td>-0.0002557865</td><td>0.3873985</td></tr>\n",
              "\t<tr><td>none</td><td>0.2</td><td>0.99796954</td><td>0.0040322581</td><td>0.6132265</td><td> 0.0024430841</td><td>0.3867735</td></tr>\n",
              "\t<tr><td>none</td><td>0.3</td><td>0.99593650</td><td>0.0120838710</td><td>0.6150947</td><td> 0.0097731869</td><td>0.3849053</td></tr>\n",
              "\t<tr><td>none</td><td>0.4</td><td>0.95472651</td><td>0.0958838710</td><td>0.6222714</td><td> 0.0596776668</td><td>0.3777286</td></tr>\n",
              "\t<tr><td>none</td><td>0.5</td><td>0.84073345</td><td>0.2755483871</td><td>0.6219570</td><td> 0.1273671169</td><td>0.3780430</td></tr>\n",
              "\t<tr><td>none</td><td>0.6</td><td>0.59853672</td><td>0.6462580645</td><td>0.6169930</td><td> 0.2328738259</td><td>0.3830070</td></tr>\n",
              "\t<tr><td>none</td><td>0.7</td><td>0.36594064</td><td>0.8573677419</td><td>0.5561537</td><td> 0.1928644578</td><td>0.4438463</td></tr>\n",
              "\t<tr><td>none</td><td>0.8</td><td>0.14912462</td><td>0.9734258065</td><td>0.4681931</td><td> 0.0986685503</td><td>0.5318069</td></tr>\n",
              "\t<tr><td>none</td><td>0.9</td><td>0.04579923</td><td>0.9983870968</td><td>0.4145355</td><td> 0.0346235504</td><td>0.5854645</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 9 × 7\n\n| parameter &lt;chr&gt; | prob_threshold &lt;dbl&gt; | Sensitivity &lt;dbl&gt; | Specificity &lt;dbl&gt; | Accuracy &lt;dbl&gt; | Kappa &lt;dbl&gt; | misclassification_error &lt;dbl&gt; |\n|---|---|---|---|---|---|---|\n| none | 0.1 | 0.99898477 | 0.0008064516 | 0.6126015 | -0.0002557865 | 0.3873985 |\n| none | 0.2 | 0.99796954 | 0.0040322581 | 0.6132265 |  0.0024430841 | 0.3867735 |\n| none | 0.3 | 0.99593650 | 0.0120838710 | 0.6150947 |  0.0097731869 | 0.3849053 |\n| none | 0.4 | 0.95472651 | 0.0958838710 | 0.6222714 |  0.0596776668 | 0.3777286 |\n| none | 0.5 | 0.84073345 | 0.2755483871 | 0.6219570 |  0.1273671169 | 0.3780430 |\n| none | 0.6 | 0.59853672 | 0.6462580645 | 0.6169930 |  0.2328738259 | 0.3830070 |\n| none | 0.7 | 0.36594064 | 0.8573677419 | 0.5561537 |  0.1928644578 | 0.4438463 |\n| none | 0.8 | 0.14912462 | 0.9734258065 | 0.4681931 |  0.0986685503 | 0.5318069 |\n| none | 0.9 | 0.04579923 | 0.9983870968 | 0.4145355 |  0.0346235504 | 0.5854645 |\n\n",
            "text/latex": "A data.frame: 9 × 7\n\\begin{tabular}{lllllll}\n parameter & prob\\_threshold & Sensitivity & Specificity & Accuracy & Kappa & misclassification\\_error\\\\\n <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t none & 0.1 & 0.99898477 & 0.0008064516 & 0.6126015 & -0.0002557865 & 0.3873985\\\\\n\t none & 0.2 & 0.99796954 & 0.0040322581 & 0.6132265 &  0.0024430841 & 0.3867735\\\\\n\t none & 0.3 & 0.99593650 & 0.0120838710 & 0.6150947 &  0.0097731869 & 0.3849053\\\\\n\t none & 0.4 & 0.95472651 & 0.0958838710 & 0.6222714 &  0.0596776668 & 0.3777286\\\\\n\t none & 0.5 & 0.84073345 & 0.2755483871 & 0.6219570 &  0.1273671169 & 0.3780430\\\\\n\t none & 0.6 & 0.59853672 & 0.6462580645 & 0.6169930 &  0.2328738259 & 0.3830070\\\\\n\t none & 0.7 & 0.36594064 & 0.8573677419 & 0.5561537 &  0.1928644578 & 0.4438463\\\\\n\t none & 0.8 & 0.14912462 & 0.9734258065 & 0.4681931 &  0.0986685503 & 0.5318069\\\\\n\t none & 0.9 & 0.04579923 & 0.9983870968 & 0.4145355 &  0.0346235504 & 0.5854645\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  parameter prob_threshold Sensitivity Specificity  Accuracy  Kappa        \n",
              "1 none      0.1            0.99898477  0.0008064516 0.6126015 -0.0002557865\n",
              "2 none      0.2            0.99796954  0.0040322581 0.6132265  0.0024430841\n",
              "3 none      0.3            0.99593650  0.0120838710 0.6150947  0.0097731869\n",
              "4 none      0.4            0.95472651  0.0958838710 0.6222714  0.0596776668\n",
              "5 none      0.5            0.84073345  0.2755483871 0.6219570  0.1273671169\n",
              "6 none      0.6            0.59853672  0.6462580645 0.6169930  0.2328738259\n",
              "7 none      0.7            0.36594064  0.8573677419 0.5561537  0.1928644578\n",
              "8 none      0.8            0.14912462  0.9734258065 0.4681931  0.0986685503\n",
              "9 none      0.9            0.04579923  0.9983870968 0.4145355  0.0346235504\n",
              "  misclassification_error\n",
              "1 0.3873985              \n",
              "2 0.3867735              \n",
              "3 0.3849053              \n",
              "4 0.3777286              \n",
              "5 0.3780430              \n",
              "6 0.3830070              \n",
              "7 0.4438463              \n",
              "8 0.5318069              \n",
              "9 0.5854645              "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, the optimal threshold that minimizes the 10-fold CV misclassification error is 0.4 at 0.3777, while the optimal threshold that maximizes kappa is 0.6 at a kappa value of 0.2329. The difference is most likely due to misclassification error focusing on raw predictions, while kappa takes into account classes and random agreement. Kappa might be favoring the higher threshold that handles the class imbalance better."
      ],
      "metadata": {
        "id": "hkNJWlDYlsSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (g)  \n",
        "(10 pts.) Using the complete data set with all 3206 observations, fit KNN classifiers with K = 5, 10,\n",
        "15, 20, 25, 30, 35, and 40 using all 8 predictors. What is the optimal value of K based on 10-fold CV\n",
        "misclassification error? Justify your response."
      ],
      "metadata": {
        "id": "daDFX3fS64JW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload the data\n",
        "mus14data <- read_csv(\"/content/mus14data.csv\")\n",
        "\n",
        "# Trim data down to using specific predictors\n",
        "select_predictors <- c(\"private\", \"retire\", \"age\", \"hstatusg\", \"hhincome\", \"educyear\", \"married\", \"hisp\", \"chronic\")\n",
        "mus14data_selected <- mus14data %>%\n",
        "  dplyr::select(all_of(select_predictors))\n",
        "\n",
        "# Center and Scale the data\n",
        "mus14data_selected_csc <- data.frame(scale(mus14data_selected[,2:9]))\n",
        "mus14data_selected_csc$private <- factor(mus14data_selected$private,\n",
        "                                         levels = c(0, 1),\n",
        "                                         labels = c(\"class0\", \"class1\"))\n",
        "\n",
        "# Dataframe of specific k values for tuneGrid\n",
        "k_values <- data.frame(k = c(5, 10, 15, 20, 25, 30, 35, 40))\n",
        "\n",
        "# 10-fold CV KNN classifier\n",
        "set.seed(1234)\n",
        "\n",
        "knn_mus14data_selected_10cv <- suppressWarnings(train(x = mus14data_selected_csc[, 1:8],\n",
        "                                                      y = mus14data_selected_csc$private,\n",
        "                                                      method = \"knn\",\n",
        "                                                      trControl = trainControl(method = \"cv\",\n",
        "                                                                               number = 10),\n",
        "                                                      tuneGrid = k_values))\n",
        "\n",
        "knn_mus14data_selected_10cv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "CTcP-loMjoE1",
        "outputId": "6576a8df-2bd7-420c-cbaf-b85ed1d65d3b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mRows: \u001b[22m\u001b[34m3206\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m35\u001b[39m\n",
            "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
            "\u001b[1mDelimiter:\u001b[22m \",\"\n",
            "\u001b[32mdbl\u001b[39m (35): personid, private, eprhi, age, hisp, white, female, educyear, marr...\n",
            "\n",
            "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
            "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "k-Nearest Neighbors \n",
              "\n",
              "3206 samples\n",
              "   8 predictor\n",
              "   2 classes: 'class0', 'class1' \n",
              "\n",
              "No pre-processing\n",
              "Resampling: Cross-Validated (10 fold) \n",
              "Summary of sample sizes: 2885, 2886, 2884, 2885, 2885, 2886, ... \n",
              "Resampling results across tuning parameters:\n",
              "\n",
              "  k   Accuracy   Kappa    \n",
              "   5  0.6060448  0.1541163\n",
              "  10  0.6004422  0.1373768\n",
              "  15  0.6060497  0.1441581\n",
              "  20  0.6069823  0.1421461\n",
              "  25  0.6016854  0.1244215\n",
              "  30  0.6063797  0.1328576\n",
              "  35  0.6076248  0.1345077\n",
              "  40  0.6116669  0.1408423\n",
              "\n",
              "Accuracy was used to select the optimal model using the largest value.\n",
              "The final value used for the model was k = 40."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the misclassification error (1 - Accuracy)\n",
        "knn_mus14data_selected_10cv_df <- as.data.frame(knn_mus14data_selected_10cv$results)\n",
        "knn_mus14data_selected_10cv_df$misclassification_error = 1 - knn_mus14data_selected_10cv_df$Accuracy\n",
        "knn_mus14data_selected_10cv_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "A5Rto2C078OX",
        "outputId": "90acc751-405a-42e8-a2fa-cc9782f324e7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 8 × 6</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>k</th><th scope=col>Accuracy</th><th scope=col>Kappa</th><th scope=col>AccuracySD</th><th scope=col>KappaSD</th><th scope=col>misclassification_error</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td> 5</td><td>0.6060448</td><td>0.1541163</td><td>0.02134927</td><td>0.04805439</td><td>0.3939552</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>10</td><td>0.6004422</td><td>0.1373768</td><td>0.03151431</td><td>0.07019562</td><td>0.3995578</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>15</td><td>0.6060497</td><td>0.1441581</td><td>0.01873625</td><td>0.04080273</td><td>0.3939503</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>20</td><td>0.6069823</td><td>0.1421461</td><td>0.02645300</td><td>0.05755657</td><td>0.3930177</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>25</td><td>0.6016854</td><td>0.1244215</td><td>0.02682351</td><td>0.06027985</td><td>0.3983146</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>30</td><td>0.6063797</td><td>0.1328576</td><td>0.02943817</td><td>0.06023496</td><td>0.3936203</td></tr>\n",
              "\t<tr><th scope=row>7</th><td>35</td><td>0.6076248</td><td>0.1345077</td><td>0.02611759</td><td>0.05760120</td><td>0.3923752</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>40</td><td>0.6116669</td><td>0.1408423</td><td>0.01613993</td><td>0.03639981</td><td>0.3883331</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 8 × 6\n\n| <!--/--> | k &lt;dbl&gt; | Accuracy &lt;dbl&gt; | Kappa &lt;dbl&gt; | AccuracySD &lt;dbl&gt; | KappaSD &lt;dbl&gt; | misclassification_error &lt;dbl&gt; |\n|---|---|---|---|---|---|---|\n| 1 |  5 | 0.6060448 | 0.1541163 | 0.02134927 | 0.04805439 | 0.3939552 |\n| 2 | 10 | 0.6004422 | 0.1373768 | 0.03151431 | 0.07019562 | 0.3995578 |\n| 3 | 15 | 0.6060497 | 0.1441581 | 0.01873625 | 0.04080273 | 0.3939503 |\n| 4 | 20 | 0.6069823 | 0.1421461 | 0.02645300 | 0.05755657 | 0.3930177 |\n| 5 | 25 | 0.6016854 | 0.1244215 | 0.02682351 | 0.06027985 | 0.3983146 |\n| 6 | 30 | 0.6063797 | 0.1328576 | 0.02943817 | 0.06023496 | 0.3936203 |\n| 7 | 35 | 0.6076248 | 0.1345077 | 0.02611759 | 0.05760120 | 0.3923752 |\n| 8 | 40 | 0.6116669 | 0.1408423 | 0.01613993 | 0.03639981 | 0.3883331 |\n\n",
            "text/latex": "A data.frame: 8 × 6\n\\begin{tabular}{r|llllll}\n  & k & Accuracy & Kappa & AccuracySD & KappaSD & misclassification\\_error\\\\\n  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t1 &  5 & 0.6060448 & 0.1541163 & 0.02134927 & 0.04805439 & 0.3939552\\\\\n\t2 & 10 & 0.6004422 & 0.1373768 & 0.03151431 & 0.07019562 & 0.3995578\\\\\n\t3 & 15 & 0.6060497 & 0.1441581 & 0.01873625 & 0.04080273 & 0.3939503\\\\\n\t4 & 20 & 0.6069823 & 0.1421461 & 0.02645300 & 0.05755657 & 0.3930177\\\\\n\t5 & 25 & 0.6016854 & 0.1244215 & 0.02682351 & 0.06027985 & 0.3983146\\\\\n\t6 & 30 & 0.6063797 & 0.1328576 & 0.02943817 & 0.06023496 & 0.3936203\\\\\n\t7 & 35 & 0.6076248 & 0.1345077 & 0.02611759 & 0.05760120 & 0.3923752\\\\\n\t8 & 40 & 0.6116669 & 0.1408423 & 0.01613993 & 0.03639981 & 0.3883331\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  k  Accuracy  Kappa     AccuracySD KappaSD    misclassification_error\n",
              "1  5 0.6060448 0.1541163 0.02134927 0.04805439 0.3939552              \n",
              "2 10 0.6004422 0.1373768 0.03151431 0.07019562 0.3995578              \n",
              "3 15 0.6060497 0.1441581 0.01873625 0.04080273 0.3939503              \n",
              "4 20 0.6069823 0.1421461 0.02645300 0.05755657 0.3930177              \n",
              "5 25 0.6016854 0.1244215 0.02682351 0.06027985 0.3983146              \n",
              "6 30 0.6063797 0.1328576 0.02943817 0.06023496 0.3936203              \n",
              "7 35 0.6076248 0.1345077 0.02611759 0.05760120 0.3923752              \n",
              "8 40 0.6116669 0.1408423 0.01613993 0.03639981 0.3883331              "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimal k based on misclassification error from the results table is k=40, where it has the smallest misclassification error of 0.388."
      ],
      "metadata": {
        "id": "gB4qc4-RLbpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (h)\n",
        " (10 pts.) Using the complete data set with all 3206 observations, fit LDA and QDA classifiers using all\n",
        "8 predictors. Compute the 10-fold CV misclassification error for each classifier. For these data, why\n",
        "might one argue that that LDA and QDA methods are inappropriate?"
      ],
      "metadata": {
        "id": "UcpvcWVRMBup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10-fold CV LDA classifier\n",
        "set.seed(1234)\n",
        "\n",
        "lda_mus14data_selected_10cv <- suppressWarnings(train(x = mus14data_selected_csc[, 1:8],\n",
        "                                                      y = mus14data_selected_csc$private,\n",
        "                                                      method = \"lda\",\n",
        "                                                      trControl = trainControl(method = \"cv\",\n",
        "                                                                               number = 10)))\n",
        "\n",
        "lda_mus14data_selected_10cv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "PP9f9ikrLlAx",
        "outputId": "804a33e5-902d-4685-941b-c4ddb7ad16ca"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Linear Discriminant Analysis \n",
              "\n",
              "3206 samples\n",
              "   8 predictor\n",
              "   2 classes: 'class0', 'class1' \n",
              "\n",
              "No pre-processing\n",
              "Resampling: Cross-Validated (10 fold) \n",
              "Summary of sample sizes: 2885, 2886, 2884, 2885, 2885, 2886, ... \n",
              "Resampling results:\n",
              "\n",
              "  Accuracy   Kappa    \n",
              "  0.6207138  0.1210944\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10-fold CV QDA classifier\n",
        "set.seed(1234)\n",
        "\n",
        "qda_mus14data_selected_10cv <- suppressWarnings(train(x = mus14data_selected_csc[, 1:8],\n",
        "                                                      y = mus14data_selected_csc$private,\n",
        "                                                      method = \"qda\",\n",
        "                                                      trControl = trainControl(method = \"cv\",\n",
        "                                                                               number = 10)))\n",
        "\n",
        "qda_mus14data_selected_10cv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "0Jk2yOFDMVYm",
        "outputId": "1c62641a-8728-4922-d294-66ee7f54ac08"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Quadratic Discriminant Analysis \n",
              "\n",
              "3206 samples\n",
              "   8 predictor\n",
              "   2 classes: 'class0', 'class1' \n",
              "\n",
              "No pre-processing\n",
              "Resampling: Cross-Validated (10 fold) \n",
              "Summary of sample sizes: 2885, 2886, 2884, 2885, 2885, 2886, ... \n",
              "Resampling results:\n",
              "\n",
              "  Accuracy   Kappa   \n",
              "  0.6010759  0.221991\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Misclassification Error Results\n",
        "lda_misclassification = 1 - lda_mus14data_selected_10cv$results$Accuracy\n",
        "qda_misclassification = 1 - qda_mus14data_selected_10cv$results$Accuracy\n",
        "\n",
        "print(paste(\"The lda_misclassification error is: \", lda_misclassification))\n",
        "print(paste(\"The qda_misclassification error is: \", qda_misclassification))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djsFFfmqPZjb",
        "outputId": "a7944149-fc0a-41ac-ae5b-825b429bd915"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"The lda_misclassification error is:  0.379286185929065\"\n",
            "[1] \"The qda_misclassification error is:  0.398924078723322\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA and QDA methods may be inappropriate for this dataset due to there being a lot of catagorical variables, since LDA and QDA handles normally distributed variables better. As seen in the KNN modeling, a k=40 performed the best, this suggests the data points may not be clearly separated, thus needing more neighbors to classify. LDA and QDA would struggle more due to its simplicity and inflexibility compared to other modeling methods."
      ],
      "metadata": {
        "id": "71xQu5PrPWGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (i)\n",
        "(5 pts.) Using the complete data set with all 3206 observations, fit a naive Bayes classifier (using\n",
        "all 8 predictors). Assume that the numerical variables are normally distributed. Use method\n",
        "= \"naive_bayes\" and tuneGrid = data.frame(laplace = 0, usekernel = FALSE, adjust =\n",
        "FALSE) in the train() function. Also, if you have not already, be sure to convert the binary 0/1\n",
        "predictors to factor variables, otherwise these predictors will be treated as numerical and therefore will be assumed to be normally distributed. Compute the 10-fold CV misclassification error for this\n",
        "classifier."
      ],
      "metadata": {
        "id": "1BJMoeMnWV3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload the data\n",
        "mus14data <- read_csv(\"/content/mus14data.csv\")\n",
        "\n",
        "# Trim data down to using specific predictors\n",
        "select_predictors <- c(\"private\", \"retire\", \"age\", \"hstatusg\", \"hhincome\", \"educyear\", \"married\", \"hisp\", \"chronic\")\n",
        "mus14data_selected <- mus14data %>%\n",
        "  dplyr::select(all_of(select_predictors))\n",
        "\n",
        "# Factor the catagorical variables\n",
        "mus14data_selected$retire <- factor(mus14data_selected$retire)\n",
        "mus14data_selected$hstatusg <- factor(mus14data_selected$hstatusg)\n",
        "mus14data_selected$married <- factor(mus14data_selected$married)\n",
        "mus14data_selected$hisp <- factor(mus14data_selected$hisp)\n",
        "mus14data_selected$private <- factor(mus14data_selected$private)\n",
        "\n",
        "# Set up the Naive Bayes tuning parameters\n",
        "nb_tunegrid <- data.frame(laplace = 0, usekernel = FALSE, adjust = FALSE)\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set.seed(1234)\n",
        "\n",
        "# Train Naive Bayes model using 10-fold cross-validation\n",
        "nb_mus14data_selected_10cv <- suppressWarnings(train(x = mus14data_selected[, 1:8],\n",
        "                                                     y = mus14data_selected$private,\n",
        "                                                     method = \"naive_bayes\",\n",
        "                                                     trControl = trainControl(method = \"cv\", number = 10),\n",
        "                                                     tuneGrid = nb_tunegrid))\n",
        "\n",
        "nb_mus14data_selected_10cv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "jQgXQiAtPAAc",
        "outputId": "33d84623-5c98-4be2-cce7-2a586b67c80f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mRows: \u001b[22m\u001b[34m3206\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m35\u001b[39m\n",
            "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
            "\u001b[1mDelimiter:\u001b[22m \",\"\n",
            "\u001b[32mdbl\u001b[39m (35): personid, private, eprhi, age, hisp, white, female, educyear, marr...\n",
            "\n",
            "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
            "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Naive Bayes \n",
              "\n",
              "3206 samples\n",
              "   8 predictor\n",
              "   2 classes: '0', '1' \n",
              "\n",
              "No pre-processing\n",
              "Resampling: Cross-Validated (10 fold) \n",
              "Summary of sample sizes: 2885, 2886, 2884, 2885, 2885, 2886, ... \n",
              "Resampling results:\n",
              "\n",
              "  Accuracy   Kappa    \n",
              "  0.9984404  0.9967171\n",
              "\n",
              "Tuning parameter 'laplace' was held constant at a value of 0\n",
              "Tuning\n",
              " parameter 'usekernel' was held constant at a value of FALSE\n",
              "Tuning\n",
              " parameter 'adjust' was held constant at a value of FALSE"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Misclassification Error Results\n",
        "bayes_misclassification = 1 - nb_mus14data_selected_10cv$results$Accuracy\n",
        "\n",
        "print(paste(\"The bayes misclassification error is: \", bayes_misclassification))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2kZMdlBYyva",
        "outputId": "d6ebeba2-4bc6-4220-9304-260affbaca2a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"The bayes misclassification error is:  0.00155957943925233\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (j)\n",
        "(2 pts.) Considering all of the classifiers from parts (e) - (h), which is best with respect to 10-fold CV\n",
        "misclassification error?"
      ],
      "metadata": {
        "id": "estEZ2hScgeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (e) Logistic Regression 10-CV\n",
        "print(paste(\"Logistic Classifier 10-CV misclassification error is: \", 1 - lr_mus14data_selected_10cv$results$Accuracy))\n",
        "print(paste(\"Logistic Classifier @ 0.4 threshold 10-CV misclassification error is: \", 1 - lr_mus14data_selected_10cv_ths[lr_mus14data_selected_10cv_ths$prob_threshold == 0.4, ]$Accuracy))\n",
        "print(paste(\"KNN Classifer @ k=40 10-CV misclassification error is: \", 1 - knn_mus14data_selected_10cv$results$Accuracy[8]))\n",
        "print(paste(\"LDA Classifier 10-CV misclassification error is: \", 1 - lda_mus14data_selected_10cv$results$Accuracy))\n",
        "print(paste(\"QDA Classifier 10-CV misclassification error is: \", 1 - qda_mus14data_selected_10cv$results$Accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScX334hAfhwv",
        "outputId": "55ff9ecd-bfc8-4aef-cf78-95da99a83819"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Logistic Classifier 10-CV misclassification error is:  0.378042982430681\"\n",
            "[1] \"Logistic Classifier @ 0.4 threshold 10-CV misclassification error is:  0.377728553530311\"\n",
            "[1] \"KNN Classifer @ k=40 10-CV misclassification error is:  0.388333109605077\"\n",
            "[1] \"LDA Classifier 10-CV misclassification error is:  0.379286185929065\"\n",
            "[1] \"QDA Classifier 10-CV misclassification error is:  0.398924078723322\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 10-fold CV model with the lowest misclassification error is Logistic Classifier @ 0.4 threshold 10-CV at a misclassification error value of 0.3777."
      ],
      "metadata": {
        "id": "WkQ9Kf4UHfGV"
      }
    }
  ]
}